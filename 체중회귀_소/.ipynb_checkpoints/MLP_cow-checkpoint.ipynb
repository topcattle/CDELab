{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13a137d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import add, Dropout, Activation, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import models\n",
    "from sklearn.metrics import r2_score\n",
    "from matplotlib.patches import Patch\n",
    "from scipy import stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c211387e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>돼지</th>\n",
       "      <th>D1</th>\n",
       "      <th>rear_W</th>\n",
       "      <th>rear_trunk_W</th>\n",
       "      <th>rear_trunk_A</th>\n",
       "      <th>trunk_W</th>\n",
       "      <th>trunk_H</th>\n",
       "      <th>trunk_A</th>\n",
       "      <th>trunk_G</th>\n",
       "      <th>trunk_front_W</th>\n",
       "      <th>...</th>\n",
       "      <th>max1</th>\n",
       "      <th>mean2</th>\n",
       "      <th>max2</th>\n",
       "      <th>mean3</th>\n",
       "      <th>max3</th>\n",
       "      <th>mean4</th>\n",
       "      <th>max4</th>\n",
       "      <th>mean5</th>\n",
       "      <th>max5</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>상관계수</td>\n",
       "      <td>0.224671</td>\n",
       "      <td>0.490432</td>\n",
       "      <td>0.53374</td>\n",
       "      <td>0.447982</td>\n",
       "      <td>0.844043</td>\n",
       "      <td>0.338332</td>\n",
       "      <td>0.818565</td>\n",
       "      <td>0.747194</td>\n",
       "      <td>0.492227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.820094</td>\n",
       "      <td>0.323015</td>\n",
       "      <td>0.171445</td>\n",
       "      <td>0.562356</td>\n",
       "      <td>0.667816</td>\n",
       "      <td>0.754422</td>\n",
       "      <td>0.781111</td>\n",
       "      <td>0.579229</td>\n",
       "      <td>0.527422</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022_08_10_164935_760_123454.pcd</td>\n",
       "      <td>1000.010000</td>\n",
       "      <td>626.300000</td>\n",
       "      <td>644.43000</td>\n",
       "      <td>437945.650000</td>\n",
       "      <td>766.350000</td>\n",
       "      <td>881.540000</td>\n",
       "      <td>536281.670000</td>\n",
       "      <td>2618.780000</td>\n",
       "      <td>635.790000</td>\n",
       "      <td>...</td>\n",
       "      <td>782.320000</td>\n",
       "      <td>846.880000</td>\n",
       "      <td>902.330000</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>478192.010000</td>\n",
       "      <td>558005.950000</td>\n",
       "      <td>2502.030000</td>\n",
       "      <td>2676.490000</td>\n",
       "      <td>760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022_08_10_164938_760_123454.pcd</td>\n",
       "      <td>1000.010000</td>\n",
       "      <td>613.800000</td>\n",
       "      <td>636.77000</td>\n",
       "      <td>423469.520000</td>\n",
       "      <td>810.680000</td>\n",
       "      <td>858.710000</td>\n",
       "      <td>546742.600000</td>\n",
       "      <td>2641.630000</td>\n",
       "      <td>686.550000</td>\n",
       "      <td>...</td>\n",
       "      <td>814.930000</td>\n",
       "      <td>829.600000</td>\n",
       "      <td>876.770000</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>492604.190000</td>\n",
       "      <td>567070.800000</td>\n",
       "      <td>2515.050000</td>\n",
       "      <td>2695.410000</td>\n",
       "      <td>760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022_08_10_164943_760_123454.pcd</td>\n",
       "      <td>1110.010000</td>\n",
       "      <td>571.620000</td>\n",
       "      <td>627.15000</td>\n",
       "      <td>421899.660000</td>\n",
       "      <td>794.610000</td>\n",
       "      <td>843.230000</td>\n",
       "      <td>531064.360000</td>\n",
       "      <td>2600.220000</td>\n",
       "      <td>650.540000</td>\n",
       "      <td>...</td>\n",
       "      <td>802.610000</td>\n",
       "      <td>847.130000</td>\n",
       "      <td>1051.280000</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>473963.160000</td>\n",
       "      <td>554214.080000</td>\n",
       "      <td>2508.900000</td>\n",
       "      <td>2869.910000</td>\n",
       "      <td>760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022_08_10_164946_760_123454.pcd</td>\n",
       "      <td>1150.010000</td>\n",
       "      <td>528.660000</td>\n",
       "      <td>565.01000</td>\n",
       "      <td>408052.190000</td>\n",
       "      <td>810.030000</td>\n",
       "      <td>855.260000</td>\n",
       "      <td>549242.080000</td>\n",
       "      <td>2634.540000</td>\n",
       "      <td>653.820000</td>\n",
       "      <td>...</td>\n",
       "      <td>821.240000</td>\n",
       "      <td>811.890000</td>\n",
       "      <td>867.840000</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>476599.320000</td>\n",
       "      <td>567133.620000</td>\n",
       "      <td>2476.310000</td>\n",
       "      <td>2680.670000</td>\n",
       "      <td>760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022_08_10_165558_760_123454.pcd</td>\n",
       "      <td>990.010000</td>\n",
       "      <td>608.000000</td>\n",
       "      <td>668.06000</td>\n",
       "      <td>459952.620000</td>\n",
       "      <td>819.000000</td>\n",
       "      <td>852.650000</td>\n",
       "      <td>552299.220000</td>\n",
       "      <td>2655.300000</td>\n",
       "      <td>666.130000</td>\n",
       "      <td>...</td>\n",
       "      <td>833.080000</td>\n",
       "      <td>869.250000</td>\n",
       "      <td>1040.390000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>498735.750000</td>\n",
       "      <td>571712.020000</td>\n",
       "      <td>2567.910000</td>\n",
       "      <td>2760.180000</td>\n",
       "      <td>760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022_08_10_165601_760_123454.pcd</td>\n",
       "      <td>970.010000</td>\n",
       "      <td>622.540000</td>\n",
       "      <td>675.94000</td>\n",
       "      <td>461765.700000</td>\n",
       "      <td>808.440000</td>\n",
       "      <td>853.450000</td>\n",
       "      <td>549666.940000</td>\n",
       "      <td>2649.290000</td>\n",
       "      <td>663.430000</td>\n",
       "      <td>...</td>\n",
       "      <td>813.320000</td>\n",
       "      <td>837.790000</td>\n",
       "      <td>864.830000</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>499497.470000</td>\n",
       "      <td>567715.080000</td>\n",
       "      <td>2537.740000</td>\n",
       "      <td>2691.140000</td>\n",
       "      <td>760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022_08_10_165754_700_123456.pcd</td>\n",
       "      <td>890.010000</td>\n",
       "      <td>650.820000</td>\n",
       "      <td>680.61000</td>\n",
       "      <td>483585.780000</td>\n",
       "      <td>801.050000</td>\n",
       "      <td>865.560000</td>\n",
       "      <td>545320.390000</td>\n",
       "      <td>2631.000000</td>\n",
       "      <td>642.490000</td>\n",
       "      <td>...</td>\n",
       "      <td>808.100000</td>\n",
       "      <td>857.220000</td>\n",
       "      <td>886.760000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>517789.490000</td>\n",
       "      <td>567286.700000</td>\n",
       "      <td>2579.130000</td>\n",
       "      <td>2676.750000</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 돼지           D1      rear_W  rear_trunk_W  \\\n",
       "0                              상관계수     0.224671    0.490432       0.53374   \n",
       "1  2022_08_10_164935_760_123454.pcd  1000.010000  626.300000     644.43000   \n",
       "2  2022_08_10_164938_760_123454.pcd  1000.010000  613.800000     636.77000   \n",
       "3  2022_08_10_164943_760_123454.pcd  1110.010000  571.620000     627.15000   \n",
       "4  2022_08_10_164946_760_123454.pcd  1150.010000  528.660000     565.01000   \n",
       "5  2022_08_10_165558_760_123454.pcd   990.010000  608.000000     668.06000   \n",
       "6  2022_08_10_165601_760_123454.pcd   970.010000  622.540000     675.94000   \n",
       "7  2022_08_10_165754_700_123456.pcd   890.010000  650.820000     680.61000   \n",
       "\n",
       "    rear_trunk_A     trunk_W     trunk_H        trunk_A      trunk_G  \\\n",
       "0       0.447982    0.844043    0.338332       0.818565     0.747194   \n",
       "1  437945.650000  766.350000  881.540000  536281.670000  2618.780000   \n",
       "2  423469.520000  810.680000  858.710000  546742.600000  2641.630000   \n",
       "3  421899.660000  794.610000  843.230000  531064.360000  2600.220000   \n",
       "4  408052.190000  810.030000  855.260000  549242.080000  2634.540000   \n",
       "5  459952.620000  819.000000  852.650000  552299.220000  2655.300000   \n",
       "6  461765.700000  808.440000  853.450000  549666.940000  2649.290000   \n",
       "7  483585.780000  801.050000  865.560000  545320.390000  2631.000000   \n",
       "\n",
       "   trunk_front_W  ...        max1       mean2         max2     mean3  \\\n",
       "0       0.492227  ...    0.820094    0.323015     0.171445  0.562356   \n",
       "1     635.790000  ...  782.320000  846.880000   902.330000  0.820000   \n",
       "2     686.550000  ...  814.930000  829.600000   876.770000  0.870000   \n",
       "3     650.540000  ...  802.610000  847.130000  1051.280000  0.820000   \n",
       "4     653.820000  ...  821.240000  811.890000   867.840000  0.870000   \n",
       "5     666.130000  ...  833.080000  869.250000  1040.390000  0.830000   \n",
       "6     663.430000  ...  813.320000  837.790000   864.830000  0.870000   \n",
       "7     642.490000  ...  808.100000  857.220000   886.760000  0.860000   \n",
       "\n",
       "       max3          mean4           max4        mean5         max5  weight  \n",
       "0  0.667816       0.754422       0.781111     0.579229     0.527422       1  \n",
       "1  0.880000  478192.010000  558005.950000  2502.030000  2676.490000     760  \n",
       "2  0.940000  492604.190000  567070.800000  2515.050000  2695.410000     760  \n",
       "3  0.950000  473963.160000  554214.080000  2508.900000  2869.910000     760  \n",
       "4  0.970000  476599.320000  567133.620000  2476.310000  2680.670000     760  \n",
       "5  0.970000  498735.750000  571712.020000  2567.910000  2760.180000     760  \n",
       "6  0.950000  499497.470000  567715.080000  2537.740000  2691.140000     760  \n",
       "7  0.940000  517789.490000  567286.700000  2579.130000  2676.750000     700  \n",
       "\n",
       "[8 rows x 25 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#파일 불러오기\n",
    "excel_data=pd.read_excel('데이터정리_취합_소.xlsx', sheet_name='ResultWeight_MainDimension', header=1)\n",
    "excel_data[0:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f72b8d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>돼지</th>\n",
       "      <th>D1</th>\n",
       "      <th>rear_W</th>\n",
       "      <th>rear_trunk_W</th>\n",
       "      <th>rear_trunk_A</th>\n",
       "      <th>trunk_W</th>\n",
       "      <th>trunk_H</th>\n",
       "      <th>trunk_A</th>\n",
       "      <th>trunk_G</th>\n",
       "      <th>trunk_front_W</th>\n",
       "      <th>...</th>\n",
       "      <th>max1</th>\n",
       "      <th>mean2</th>\n",
       "      <th>max2</th>\n",
       "      <th>mean3</th>\n",
       "      <th>max3</th>\n",
       "      <th>mean4</th>\n",
       "      <th>max4</th>\n",
       "      <th>mean5</th>\n",
       "      <th>max5</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>상관계수</td>\n",
       "      <td>0.224671</td>\n",
       "      <td>0.490432</td>\n",
       "      <td>0.53374</td>\n",
       "      <td>0.447982</td>\n",
       "      <td>0.844043</td>\n",
       "      <td>0.338332</td>\n",
       "      <td>0.818565</td>\n",
       "      <td>0.747194</td>\n",
       "      <td>0.492227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.820094</td>\n",
       "      <td>0.323015</td>\n",
       "      <td>0.171445</td>\n",
       "      <td>0.562356</td>\n",
       "      <td>0.667816</td>\n",
       "      <td>0.754422</td>\n",
       "      <td>0.781111</td>\n",
       "      <td>0.579229</td>\n",
       "      <td>0.527422</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     돼지        D1    rear_W  rear_trunk_W  rear_trunk_A   trunk_W   trunk_H  \\\n",
       "0  상관계수  0.224671  0.490432       0.53374      0.447982  0.844043  0.338332   \n",
       "\n",
       "    trunk_A   trunk_G  trunk_front_W  ...      max1     mean2      max2  \\\n",
       "0  0.818565  0.747194       0.492227  ...  0.820094  0.323015  0.171445   \n",
       "\n",
       "      mean3      max3     mean4      max4     mean5      max5  weight  \n",
       "0  0.562356  0.667816  0.754422  0.781111  0.579229  0.527422       1  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#무게와 치수와 가지는 상관관계 확인\n",
    "data=excel_data[1:]\n",
    "corr=excel_data[0:1]\n",
    "\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfef876d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#면적, 너비, 높이, 둘레 관련 데이터끼리 묶기\n",
    "data_rear=pd.concat([data['rear_W']], axis=1)\n",
    "data_rear_trunk=pd.concat([data['rear_trunk_W'], data['rear_trunk_W']], axis=1)\n",
    "data_trunk=pd.concat([data['trunk_W'], data['trunk_H'], data['trunk_A'],data['trunk_G']], axis=1)\n",
    "data_trunk_front=pd.concat([data['trunk_front_W'], data['trunk_front_H'], data['trunk_front_A'],data['trunk_front_G']], axis=1)\n",
    "data_front=pd.concat([data['front_W']], axis=1)\n",
    "data_mean=pd.concat([data['mean1'], data['mean2'], data['mean3'],data['mean4'], data['mean5']], axis=1)\n",
    "data_max=pd.concat([data['max1'], data['max2'], data['max3'],data['max4'], data['max5']], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6446e264",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모든 변수를 입력변수로 넣기\n",
    "data_All=pd.concat([data_rear,data_rear_trunk,data_trunk,data_trunk_front,data_front, data_mean, data_max], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "138a442b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data70=pd.concat([data['trunk_W'], data['trunk_A'], data['trunk_G'], \n",
    "                  #data['mean1'], data['max1'], data['mean4'], data['max4']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83a9e704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력변수 X(치수), 출력변수 Y(무게)\n",
    "X=data_All\n",
    "Y=data['weight']\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42c1a959",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 타입 맞추기 (Y값 dataframe 씌우기)\n",
    "Y_train=pd.DataFrame(Y_train)\n",
    "Y_test=pd.DataFrame(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b693126",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MinMaxScaler 사용하여 데이터 정규화, scaler1은 X, scaler2는 Y 정규화에 쓰일 예정\n",
    "scaler1= MinMaxScaler()\n",
    "scaler2= MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0e81726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler1.fit(X_train)\n",
    "scaler1.fit(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4123e23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler1.transform(X_train)\n",
    "X_test_scaled=scaler1.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1bf5fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = scaler1.fit_transform(X_train)\n",
    "Y_scaled = scaler2.fit_transform(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6cadf290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler2.fit(Y_train)\n",
    "scaler2.fit(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "540ba3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_scaled = scaler2.transform(Y_train)\n",
    "Y_test_scaled=scaler2.transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "88f75df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 22)                506       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 11)                253       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 771\n",
      "Trainable params: 771\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#모델 설계하기\n",
    "#4개의 은닉층으로 구성된 Multi-layer-perceptron 모델\n",
    "#입력층과 은닉층의 노드 갯수는 34개이며, 출력층의 노드는 1개\n",
    "model = models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(X_scaled.shape[1], input_dim =X_scaled.shape[1],activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(X.shape[1]/2,activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(1,  activation='sigmoid'))\n",
    "optimize = tf.keras.optimizers.Adam(lr=0.01)\n",
    "model.compile(loss='mse', optimizer=optimize, metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a0509725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "8/8 [==============================] - 1s 2ms/step - loss: 0.0636 - acc: 0.1084\n",
      "Epoch 2/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0467 - acc: 0.1044\n",
      "Epoch 3/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0327 - acc: 0.1205\n",
      "Epoch 4/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0300 - acc: 0.1205\n",
      "Epoch 5/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0263 - acc: 0.1205\n",
      "Epoch 6/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0232 - acc: 0.1205\n",
      "Epoch 7/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0214 - acc: 0.1205\n",
      "Epoch 8/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0209 - acc: 0.1205\n",
      "Epoch 9/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0198 - acc: 0.1205\n",
      "Epoch 10/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0190 - acc: 0.1205\n",
      "Epoch 11/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0190 - acc: 0.1205\n",
      "Epoch 12/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0181 - acc: 0.1205\n",
      "Epoch 13/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0177 - acc: 0.1205\n",
      "Epoch 14/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0194 - acc: 0.1205\n",
      "Epoch 15/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0174 - acc: 0.1205\n",
      "Epoch 16/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0167 - acc: 0.1205\n",
      "Epoch 17/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0173 - acc: 0.1205\n",
      "Epoch 18/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0167 - acc: 0.1205\n",
      "Epoch 19/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0166 - acc: 0.1205\n",
      "Epoch 20/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0158 - acc: 0.1205\n",
      "Epoch 21/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0160 - acc: 0.1205\n",
      "Epoch 22/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0157 - acc: 0.1205\n",
      "Epoch 23/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0178 - acc: 0.1205\n",
      "Epoch 24/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0165 - acc: 0.1205\n",
      "Epoch 25/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0151 - acc: 0.1205\n",
      "Epoch 26/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0145 - acc: 0.1205\n",
      "Epoch 27/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0151 - acc: 0.1205\n",
      "Epoch 28/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0156 - acc: 0.1205\n",
      "Epoch 29/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0142 - acc: 0.1205\n",
      "Epoch 30/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0141 - acc: 0.1205\n",
      "Epoch 31/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0132 - acc: 0.1205\n",
      "Epoch 32/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0157 - acc: 0.1205\n",
      "Epoch 33/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0182 - acc: 0.1205\n",
      "Epoch 34/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0165 - acc: 0.1205\n",
      "Epoch 35/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0196 - acc: 0.1205\n",
      "Epoch 36/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0196 - acc: 0.1205\n",
      "Epoch 37/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0153 - acc: 0.1205\n",
      "Epoch 38/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0140 - acc: 0.1205\n",
      "Epoch 39/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0135 - acc: 0.1205\n",
      "Epoch 40/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0143 - acc: 0.1205\n",
      "Epoch 41/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0152 - acc: 0.1205\n",
      "Epoch 42/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0130 - acc: 0.1205\n",
      "Epoch 43/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0133 - acc: 0.1205\n",
      "Epoch 44/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0119 - acc: 0.1205\n",
      "Epoch 45/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0139 - acc: 0.1205\n",
      "Epoch 46/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0151 - acc: 0.1205\n",
      "Epoch 47/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0132 - acc: 0.1205\n",
      "Epoch 48/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0144 - acc: 0.1205\n",
      "Epoch 49/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0144 - acc: 0.1205\n",
      "Epoch 50/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0109 - acc: 0.1205\n",
      "Epoch 51/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0121 - acc: 0.1205\n",
      "Epoch 52/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0112 - acc: 0.1205\n",
      "Epoch 53/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0116 - acc: 0.1205\n",
      "Epoch 54/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0107 - acc: 0.1205\n",
      "Epoch 55/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0113 - acc: 0.1205\n",
      "Epoch 56/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0139 - acc: 0.1205\n",
      "Epoch 57/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0138 - acc: 0.1205\n",
      "Epoch 58/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0106 - acc: 0.1205\n",
      "Epoch 59/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0116 - acc: 0.1205\n",
      "Epoch 60/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0104 - acc: 0.1205\n",
      "Epoch 61/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0108 - acc: 0.1205\n",
      "Epoch 62/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0097 - acc: 0.1205\n",
      "Epoch 63/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0106 - acc: 0.1205\n",
      "Epoch 64/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0113 - acc: 0.1205\n",
      "Epoch 65/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0099 - acc: 0.1205\n",
      "Epoch 66/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0099 - acc: 0.1205\n",
      "Epoch 67/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0093 - acc: 0.1205\n",
      "Epoch 68/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0092 - acc: 0.1205\n",
      "Epoch 69/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0090 - acc: 0.1205\n",
      "Epoch 70/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0100 - acc: 0.1205\n",
      "Epoch 71/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0112 - acc: 0.1205\n",
      "Epoch 72/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0113 - acc: 0.1205\n",
      "Epoch 73/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0109 - acc: 0.1205\n",
      "Epoch 74/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0096 - acc: 0.1205\n",
      "Epoch 75/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0091 - acc: 0.1205\n",
      "Epoch 76/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0099 - acc: 0.1205\n",
      "Epoch 77/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0092 - acc: 0.1205\n",
      "Epoch 78/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0102 - acc: 0.1205\n",
      "Epoch 79/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0098 - acc: 0.1205\n",
      "Epoch 80/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0084 - acc: 0.1205\n",
      "Epoch 81/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0088 - acc: 0.1205\n",
      "Epoch 82/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0086 - acc: 0.1205\n",
      "Epoch 83/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0086 - acc: 0.1205\n",
      "Epoch 84/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0110 - acc: 0.1205\n",
      "Epoch 85/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0133 - acc: 0.1205\n",
      "Epoch 86/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0105 - acc: 0.1205\n",
      "Epoch 87/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0090 - acc: 0.1205\n",
      "Epoch 88/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0090 - acc: 0.1205\n",
      "Epoch 89/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0079 - acc: 0.1205\n",
      "Epoch 90/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0098 - acc: 0.1205\n",
      "Epoch 91/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0083 - acc: 0.1205\n",
      "Epoch 92/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0077 - acc: 0.1205\n",
      "Epoch 93/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0082 - acc: 0.1205\n",
      "Epoch 94/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0099 - acc: 0.1205\n",
      "Epoch 95/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0080 - acc: 0.1205\n",
      "Epoch 96/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0085 - acc: 0.1205\n",
      "Epoch 97/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0082 - acc: 0.1205\n",
      "Epoch 98/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0082 - acc: 0.1205\n",
      "Epoch 99/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0073 - acc: 0.1205\n",
      "Epoch 100/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0070 - acc: 0.1205\n",
      "Epoch 101/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0076 - acc: 0.1205\n",
      "Epoch 102/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0073 - acc: 0.1205\n",
      "Epoch 103/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0074 - acc: 0.1205\n",
      "Epoch 104/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0081 - acc: 0.1205\n",
      "Epoch 105/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0072 - acc: 0.1205\n",
      "Epoch 106/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0088 - acc: 0.1205\n",
      "Epoch 107/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0075 - acc: 0.1205\n",
      "Epoch 108/300\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0068 - acc: 0.1205\n",
      "Epoch 109/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0072 - acc: 0.1205\n",
      "Epoch 110/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0076 - acc: 0.1205\n",
      "Epoch 111/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0081 - acc: 0.1205\n",
      "Epoch 112/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0069 - acc: 0.1205\n",
      "Epoch 113/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0093 - acc: 0.1205\n",
      "Epoch 114/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0084 - acc: 0.1205\n",
      "Epoch 115/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0083 - acc: 0.1205\n",
      "Epoch 116/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0080 - acc: 0.1205\n",
      "Epoch 117/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0091 - acc: 0.1205\n",
      "Epoch 118/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0088 - acc: 0.1205\n",
      "Epoch 119/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0084 - acc: 0.1205\n",
      "Epoch 120/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0072 - acc: 0.1205\n",
      "Epoch 121/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0079 - acc: 0.1205\n",
      "Epoch 122/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0084 - acc: 0.1205\n",
      "Epoch 123/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0068 - acc: 0.1205\n",
      "Epoch 124/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0065 - acc: 0.1205\n",
      "Epoch 125/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0057 - acc: 0.1205\n",
      "Epoch 126/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0062 - acc: 0.1205\n",
      "Epoch 127/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0063 - acc: 0.1205\n",
      "Epoch 128/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0059 - acc: 0.1205\n",
      "Epoch 129/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0061 - acc: 0.1205\n",
      "Epoch 130/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0062 - acc: 0.1205\n",
      "Epoch 131/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0067 - acc: 0.1205\n",
      "Epoch 132/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0059 - acc: 0.1205\n",
      "Epoch 133/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0059 - acc: 0.1205\n",
      "Epoch 134/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0059 - acc: 0.1205\n",
      "Epoch 135/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0058 - acc: 0.1205\n",
      "Epoch 136/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0056 - acc: 0.1205\n",
      "Epoch 137/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0060 - acc: 0.1205\n",
      "Epoch 138/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0053 - acc: 0.1205\n",
      "Epoch 139/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0057 - acc: 0.1205\n",
      "Epoch 140/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0056 - acc: 0.1205\n",
      "Epoch 141/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0054 - acc: 0.1205\n",
      "Epoch 142/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0056 - acc: 0.1205\n",
      "Epoch 143/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0066 - acc: 0.1205\n",
      "Epoch 144/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0064 - acc: 0.1205\n",
      "Epoch 145/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0055 - acc: 0.1205\n",
      "Epoch 146/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0051 - acc: 0.1205\n",
      "Epoch 147/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0053 - acc: 0.1205\n",
      "Epoch 148/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0055 - acc: 0.1205\n",
      "Epoch 149/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0054 - acc: 0.1205\n",
      "Epoch 150/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0052 - acc: 0.1205\n",
      "Epoch 151/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0059 - acc: 0.1205\n",
      "Epoch 152/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0063 - acc: 0.1205\n",
      "Epoch 153/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0071 - acc: 0.1205\n",
      "Epoch 154/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0085 - acc: 0.1205\n",
      "Epoch 155/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0090 - acc: 0.1205\n",
      "Epoch 156/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0094 - acc: 0.1205\n",
      "Epoch 157/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0111 - acc: 0.1205\n",
      "Epoch 158/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0087 - acc: 0.1205\n",
      "Epoch 159/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0069 - acc: 0.1205\n",
      "Epoch 160/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0071 - acc: 0.1205\n",
      "Epoch 161/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0070 - acc: 0.1205\n",
      "Epoch 162/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0063 - acc: 0.1205\n",
      "Epoch 163/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0058 - acc: 0.1205\n",
      "Epoch 164/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0057 - acc: 0.1205\n",
      "Epoch 165/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0053 - acc: 0.1205\n",
      "Epoch 166/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0050 - acc: 0.1205\n",
      "Epoch 167/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0051 - acc: 0.1205\n",
      "Epoch 168/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0049 - acc: 0.1205\n",
      "Epoch 169/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0049 - acc: 0.1205\n",
      "Epoch 170/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0062 - acc: 0.1205\n",
      "Epoch 171/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0078 - acc: 0.1205\n",
      "Epoch 172/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0107 - acc: 0.1205\n",
      "Epoch 173/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0087 - acc: 0.1205\n",
      "Epoch 174/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0077 - acc: 0.1205\n",
      "Epoch 175/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0073 - acc: 0.1205\n",
      "Epoch 176/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0052 - acc: 0.1205\n",
      "Epoch 177/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0054 - acc: 0.1205\n",
      "Epoch 178/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0060 - acc: 0.1205\n",
      "Epoch 179/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0082 - acc: 0.1205\n",
      "Epoch 180/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0094 - acc: 0.1205\n",
      "Epoch 181/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0079 - acc: 0.1205\n",
      "Epoch 182/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0092 - acc: 0.1205\n",
      "Epoch 183/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0078 - acc: 0.1205\n",
      "Epoch 184/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0084 - acc: 0.1205\n",
      "Epoch 185/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0079 - acc: 0.1205\n",
      "Epoch 186/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0076 - acc: 0.1205\n",
      "Epoch 187/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0062 - acc: 0.1205\n",
      "Epoch 188/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0073 - acc: 0.1205\n",
      "Epoch 189/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0080 - acc: 0.1205\n",
      "Epoch 190/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0065 - acc: 0.1205\n",
      "Epoch 191/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0063 - acc: 0.1205\n",
      "Epoch 192/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0058 - acc: 0.1205\n",
      "Epoch 193/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0072 - acc: 0.1205\n",
      "Epoch 194/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0072 - acc: 0.1205\n",
      "Epoch 195/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0073 - acc: 0.1205\n",
      "Epoch 196/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0068 - acc: 0.1205\n",
      "Epoch 197/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0077 - acc: 0.1205\n",
      "Epoch 198/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0055 - acc: 0.1205\n",
      "Epoch 199/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0060 - acc: 0.1205\n",
      "Epoch 200/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0067 - acc: 0.1205\n",
      "Epoch 201/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0064 - acc: 0.1205\n",
      "Epoch 202/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0059 - acc: 0.1205\n",
      "Epoch 203/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0061 - acc: 0.1205\n",
      "Epoch 204/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0051 - acc: 0.1205\n",
      "Epoch 205/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0049 - acc: 0.1205\n",
      "Epoch 206/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0052 - acc: 0.1205\n",
      "Epoch 207/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0049 - acc: 0.1205\n",
      "Epoch 208/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0052 - acc: 0.1205\n",
      "Epoch 209/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0050 - acc: 0.1205\n",
      "Epoch 210/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0047 - acc: 0.1205\n",
      "Epoch 211/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0046 - acc: 0.1205\n",
      "Epoch 212/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0049 - acc: 0.1205\n",
      "Epoch 213/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0050 - acc: 0.1205\n",
      "Epoch 214/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0053 - acc: 0.1205\n",
      "Epoch 215/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0056 - acc: 0.1205\n",
      "Epoch 216/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0071 - acc: 0.1205\n",
      "Epoch 217/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0056 - acc: 0.1205\n",
      "Epoch 218/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0058 - acc: 0.1205\n",
      "Epoch 219/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0052 - acc: 0.1205\n",
      "Epoch 220/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0049 - acc: 0.1205\n",
      "Epoch 221/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0047 - acc: 0.1205\n",
      "Epoch 222/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0046 - acc: 0.1205\n",
      "Epoch 223/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0046 - acc: 0.1205\n",
      "Epoch 224/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0043 - acc: 0.1205\n",
      "Epoch 225/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0046 - acc: 0.1205\n",
      "Epoch 226/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0050 - acc: 0.1205\n",
      "Epoch 227/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0056 - acc: 0.1205\n",
      "Epoch 228/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0047 - acc: 0.1205\n",
      "Epoch 229/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0046 - acc: 0.1205\n",
      "Epoch 230/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0048 - acc: 0.1205\n",
      "Epoch 231/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0048 - acc: 0.1205\n",
      "Epoch 232/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0051 - acc: 0.1205\n",
      "Epoch 233/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0049 - acc: 0.1205\n",
      "Epoch 234/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0046 - acc: 0.1205\n",
      "Epoch 235/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0048 - acc: 0.1205\n",
      "Epoch 236/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0059 - acc: 0.1205\n",
      "Epoch 237/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0065 - acc: 0.1205\n",
      "Epoch 238/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0052 - acc: 0.1205\n",
      "Epoch 239/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0046 - acc: 0.1205\n",
      "Epoch 240/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0051 - acc: 0.1205\n",
      "Epoch 241/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0052 - acc: 0.1205\n",
      "Epoch 242/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0053 - acc: 0.1205\n",
      "Epoch 243/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0047 - acc: 0.1205\n",
      "Epoch 244/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0047 - acc: 0.1205\n",
      "Epoch 245/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0045 - acc: 0.1205\n",
      "Epoch 246/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0044 - acc: 0.1205\n",
      "Epoch 247/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0049 - acc: 0.1205\n",
      "Epoch 248/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0054 - acc: 0.1205\n",
      "Epoch 249/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0049 - acc: 0.1205\n",
      "Epoch 250/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0058 - acc: 0.1205\n",
      "Epoch 251/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0047 - acc: 0.1205\n",
      "Epoch 252/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0057 - acc: 0.1205\n",
      "Epoch 253/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0061 - acc: 0.1205\n",
      "Epoch 254/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0053 - acc: 0.1205\n",
      "Epoch 255/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0051 - acc: 0.1205\n",
      "Epoch 256/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0063 - acc: 0.1205\n",
      "Epoch 257/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0065 - acc: 0.1205\n",
      "Epoch 258/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0048 - acc: 0.1205\n",
      "Epoch 259/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0048 - acc: 0.1205\n",
      "Epoch 260/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0046 - acc: 0.1205\n",
      "Epoch 261/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0043 - acc: 0.1205\n",
      "Epoch 262/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0047 - acc: 0.1205\n",
      "Epoch 263/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0046 - acc: 0.1205\n",
      "Epoch 264/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0045 - acc: 0.1205\n",
      "Epoch 265/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0042 - acc: 0.1205\n",
      "Epoch 266/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0042 - acc: 0.1205\n",
      "Epoch 267/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0050 - acc: 0.1205\n",
      "Epoch 268/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0051 - acc: 0.1205\n",
      "Epoch 269/300\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0047 - acc: 0.1205\n",
      "Epoch 270/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0046 - acc: 0.1205\n",
      "Epoch 271/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0044 - acc: 0.1205\n",
      "Epoch 272/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0044 - acc: 0.1205\n",
      "Epoch 273/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0042 - acc: 0.1205\n",
      "Epoch 274/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0042 - acc: 0.1205\n",
      "Epoch 275/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0042 - acc: 0.1205\n",
      "Epoch 276/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0042 - acc: 0.1205\n",
      "Epoch 277/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0044 - acc: 0.1205\n",
      "Epoch 278/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0042 - acc: 0.1205\n",
      "Epoch 279/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0041 - acc: 0.1205\n",
      "Epoch 280/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0040 - acc: 0.1205\n",
      "Epoch 281/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0042 - acc: 0.1205\n",
      "Epoch 282/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0040 - acc: 0.1205\n",
      "Epoch 283/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0041 - acc: 0.1205\n",
      "Epoch 284/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0040 - acc: 0.1205\n",
      "Epoch 285/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0039 - acc: 0.1205\n",
      "Epoch 286/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0042 - acc: 0.1205\n",
      "Epoch 287/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0043 - acc: 0.1205\n",
      "Epoch 288/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0046 - acc: 0.1205\n",
      "Epoch 289/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0044 - acc: 0.1205\n",
      "Epoch 290/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0044 - acc: 0.1205\n",
      "Epoch 291/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0046 - acc: 0.1205\n",
      "Epoch 292/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0047 - acc: 0.1205\n",
      "Epoch 293/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0048 - acc: 0.1205\n",
      "Epoch 294/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0041 - acc: 0.1205\n",
      "Epoch 295/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0039 - acc: 0.1205\n",
      "Epoch 296/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0041 - acc: 0.1205\n",
      "Epoch 297/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0041 - acc: 0.1205\n",
      "Epoch 298/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0042 - acc: 0.1205\n",
      "Epoch 299/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0039 - acc: 0.1205\n",
      "Epoch 300/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0042 - acc: 0.1205\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0408 - acc: 0.1429\n"
     ]
    }
   ],
   "source": [
    "#모델 실행\n",
    "model.fit(X_scaled, Y_scaled, epochs=300)\n",
    "loss_and_metrics_scaled = model.evaluate(X_test_scaled,Y_test_scaled)\n",
    "loss_and_metrics = scaler2.inverse_transform([loss_and_metrics_scaled]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c970e557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 997us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "#Y 예측값\n",
    "Y_train_pred_scaled=model.predict(X_train_scaled)\n",
    "Y_test_pred= model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a106866c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.97219160e-02],\n",
       "       [2.90864766e-01],\n",
       "       [9.02532756e-01],\n",
       "       [4.86912698e-01],\n",
       "       [5.82910359e-01],\n",
       "       [3.85291278e-01],\n",
       "       [5.66447258e-01],\n",
       "       [3.13249320e-01],\n",
       "       [4.36454326e-01],\n",
       "       [8.66090953e-01],\n",
       "       [1.90590799e-01],\n",
       "       [2.93485403e-01],\n",
       "       [4.80130374e-01],\n",
       "       [1.49909745e-03],\n",
       "       [2.63329178e-01],\n",
       "       [4.64042239e-02],\n",
       "       [6.56134307e-01],\n",
       "       [1.86672896e-01],\n",
       "       [5.20075142e-01],\n",
       "       [4.85201329e-01],\n",
       "       [9.23360705e-01],\n",
       "       [5.01173019e-01],\n",
       "       [4.76983994e-01],\n",
       "       [6.59004040e-03],\n",
       "       [2.10824624e-01],\n",
       "       [1.30454466e-01],\n",
       "       [2.95173794e-01],\n",
       "       [3.55032235e-01],\n",
       "       [2.46325001e-01],\n",
       "       [4.34003145e-01],\n",
       "       [8.76986049e-03],\n",
       "       [4.85831499e-01],\n",
       "       [9.20232058e-01],\n",
       "       [4.81522754e-02],\n",
       "       [9.00410354e-01],\n",
       "       [4.90686685e-01],\n",
       "       [1.57206450e-04],\n",
       "       [5.23681521e-01],\n",
       "       [4.56582725e-01],\n",
       "       [1.27820149e-01],\n",
       "       [3.65333945e-01],\n",
       "       [4.20684934e-01],\n",
       "       [4.88537222e-01],\n",
       "       [4.20827389e-01],\n",
       "       [3.34972143e-01],\n",
       "       [3.41001868e-01],\n",
       "       [7.73449421e-01],\n",
       "       [6.34781420e-01],\n",
       "       [2.89061546e-01],\n",
       "       [5.15085757e-01],\n",
       "       [2.71571338e-01],\n",
       "       [9.10926223e-01],\n",
       "       [8.71532440e-01],\n",
       "       [9.00033489e-02],\n",
       "       [5.92168510e-01],\n",
       "       [9.28615391e-01],\n",
       "       [3.84072393e-01],\n",
       "       [1.42109646e-02],\n",
       "       [5.69873303e-02],\n",
       "       [5.05997479e-01],\n",
       "       [6.16886377e-01],\n",
       "       [5.03489912e-01],\n",
       "       [7.21735731e-02],\n",
       "       [9.45310056e-01],\n",
       "       [8.57140541e-01],\n",
       "       [4.29194748e-01],\n",
       "       [9.18023825e-01],\n",
       "       [1.52698895e-02],\n",
       "       [1.28747551e-02],\n",
       "       [4.91922498e-01],\n",
       "       [6.12415979e-03],\n",
       "       [3.16089451e-01],\n",
       "       [4.91922498e-01],\n",
       "       [3.58172834e-01],\n",
       "       [2.88472950e-01],\n",
       "       [9.92091279e-03],\n",
       "       [1.77750617e-01],\n",
       "       [3.97821963e-01],\n",
       "       [4.91768837e-01],\n",
       "       [9.25536036e-01],\n",
       "       [9.23590183e-01],\n",
       "       [2.77000159e-01],\n",
       "       [5.46386838e-01],\n",
       "       [4.75300342e-01],\n",
       "       [4.94017512e-01],\n",
       "       [3.40333998e-01],\n",
       "       [5.63808560e-01],\n",
       "       [5.02445698e-01],\n",
       "       [4.47313696e-01],\n",
       "       [5.31575441e-01],\n",
       "       [4.94190631e-03],\n",
       "       [1.62126869e-02],\n",
       "       [7.58254290e-01],\n",
       "       [1.82702169e-01],\n",
       "       [4.91922557e-01],\n",
       "       [6.16760671e-01],\n",
       "       [4.75107104e-01],\n",
       "       [5.31444192e-01],\n",
       "       [3.68116438e-01],\n",
       "       [6.83193743e-01],\n",
       "       [9.75952089e-01],\n",
       "       [5.36791205e-01],\n",
       "       [4.41080928e-01],\n",
       "       [5.26930928e-01],\n",
       "       [5.02317309e-01],\n",
       "       [4.75555956e-01],\n",
       "       [5.10290921e-01],\n",
       "       [4.16378736e-01],\n",
       "       [2.57382900e-01],\n",
       "       [2.10921139e-01],\n",
       "       [9.67844069e-01],\n",
       "       [2.91872229e-02],\n",
       "       [9.38340306e-01],\n",
       "       [6.08861968e-02],\n",
       "       [4.58301365e-01],\n",
       "       [2.72932976e-01],\n",
       "       [4.41407770e-01],\n",
       "       [5.79743505e-01],\n",
       "       [4.62098211e-01],\n",
       "       [4.36338782e-01],\n",
       "       [5.00164151e-01],\n",
       "       [4.30552334e-01],\n",
       "       [5.02445698e-01],\n",
       "       [1.95125088e-01],\n",
       "       [4.30071682e-01],\n",
       "       [5.16223311e-01],\n",
       "       [2.45197564e-01],\n",
       "       [2.40966722e-01],\n",
       "       [3.63766998e-01],\n",
       "       [8.47723424e-01],\n",
       "       [6.59727633e-01],\n",
       "       [4.52843577e-01],\n",
       "       [8.13881755e-01],\n",
       "       [6.99707866e-02],\n",
       "       [7.56511688e-02],\n",
       "       [4.39371526e-01],\n",
       "       [2.22527876e-01],\n",
       "       [8.55218768e-01],\n",
       "       [4.64330047e-01],\n",
       "       [4.27755594e-01],\n",
       "       [9.63313878e-01],\n",
       "       [4.51943219e-01],\n",
       "       [4.85518306e-01],\n",
       "       [4.32617038e-01],\n",
       "       [4.98164475e-01],\n",
       "       [5.27824640e-01],\n",
       "       [7.27192834e-02],\n",
       "       [3.21213543e-01],\n",
       "       [2.12063882e-02],\n",
       "       [4.03874591e-02],\n",
       "       [9.85121056e-02],\n",
       "       [8.20572913e-01],\n",
       "       [4.80054706e-01],\n",
       "       [5.29128671e-01],\n",
       "       [4.61135596e-01],\n",
       "       [5.37130475e-01],\n",
       "       [3.78766984e-01],\n",
       "       [9.34064627e-01],\n",
       "       [2.29934067e-01],\n",
       "       [4.65026826e-01],\n",
       "       [2.93670446e-02],\n",
       "       [5.28587759e-01],\n",
       "       [4.03857440e-01],\n",
       "       [8.23567510e-02],\n",
       "       [4.87994105e-01],\n",
       "       [9.30910647e-01],\n",
       "       [4.41121250e-01],\n",
       "       [4.94284958e-01],\n",
       "       [2.71734357e-01],\n",
       "       [5.18884540e-01],\n",
       "       [3.06399405e-01],\n",
       "       [3.35862637e-01],\n",
       "       [4.65124309e-01],\n",
       "       [5.26537895e-01],\n",
       "       [5.02445698e-01],\n",
       "       [2.61824459e-01],\n",
       "       [4.50553507e-01],\n",
       "       [4.33453649e-01],\n",
       "       [1.88075811e-01],\n",
       "       [8.06101859e-02],\n",
       "       [9.19035673e-01],\n",
       "       [2.90116251e-01],\n",
       "       [2.24585220e-01],\n",
       "       [4.36716169e-01],\n",
       "       [6.62474111e-02],\n",
       "       [4.61493433e-01],\n",
       "       [5.14456391e-01],\n",
       "       [2.46789053e-01],\n",
       "       [2.45317400e-01],\n",
       "       [8.05864394e-01],\n",
       "       [9.62375224e-01],\n",
       "       [2.03446135e-01],\n",
       "       [4.02282387e-01],\n",
       "       [9.48414028e-01],\n",
       "       [9.25517261e-01],\n",
       "       [5.89071333e-01],\n",
       "       [5.10091722e-01],\n",
       "       [2.71578968e-01],\n",
       "       [9.14481282e-01],\n",
       "       [4.35127854e-01],\n",
       "       [4.48540747e-01],\n",
       "       [1.48791626e-01],\n",
       "       [1.50047079e-01],\n",
       "       [8.85900795e-01],\n",
       "       [5.18788218e-01],\n",
       "       [3.16722184e-01],\n",
       "       [2.85636872e-01],\n",
       "       [4.25686449e-01],\n",
       "       [4.37756419e-01],\n",
       "       [4.66209024e-01],\n",
       "       [8.32702100e-01],\n",
       "       [5.63166976e-01],\n",
       "       [6.18515611e-02],\n",
       "       [1.37396958e-02],\n",
       "       [3.55152398e-01],\n",
       "       [5.10290921e-01],\n",
       "       [5.24695098e-01],\n",
       "       [1.43619464e-03],\n",
       "       [4.05317307e-01],\n",
       "       [9.45941925e-01],\n",
       "       [5.10691404e-01],\n",
       "       [3.13301891e-01],\n",
       "       [5.28465986e-01],\n",
       "       [3.19586933e-01],\n",
       "       [3.14531595e-01],\n",
       "       [1.26810521e-02],\n",
       "       [2.49657527e-01],\n",
       "       [5.86731195e-01],\n",
       "       [7.13442147e-01],\n",
       "       [8.62194836e-01],\n",
       "       [1.42784789e-01],\n",
       "       [9.79669243e-02],\n",
       "       [5.29128671e-01],\n",
       "       [2.44536385e-01],\n",
       "       [8.87440026e-01],\n",
       "       [3.54426652e-01],\n",
       "       [4.46423739e-01],\n",
       "       [2.75552928e-01],\n",
       "       [1.03882812e-01],\n",
       "       [5.64306498e-01],\n",
       "       [2.87800014e-01],\n",
       "       [2.63578415e-01],\n",
       "       [5.38392186e-01],\n",
       "       [4.39140648e-01],\n",
       "       [2.19055116e-01],\n",
       "       [2.82821178e-01],\n",
       "       [3.85656469e-02],\n",
       "       [6.48889422e-01],\n",
       "       [1.48144424e-01]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_pred_scaled #정규화 된 값 역변환 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f29b68af",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred = scaler2.inverse_transform(Y_train_pred_scaled)\n",
    "Y_test_pred = scaler2.inverse_transform(Y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d5f9a67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "weight    3.457379\n",
       "dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#훈련데이터 오차율\n",
    "train_error_rate=np.mean(abs(Y_train_pred-Y_train)*100/Y_train)\n",
    "train_error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "feeb07c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "weight    4.133673\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#검증데이터 오차율\n",
    "error_rate=np.mean(abs(Y_test_pred-Y_test)*100/Y_test)\n",
    "error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cda3318e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.424840158031234"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#회귀모델의 척도로 결정계수 확인\n",
    "R2=r2_score(Y_test, Y_test_pred)\n",
    "R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "92e345eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.81300588304251"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RMSE 구하기\n",
    "from sklearn.metrics import mean_squared_error\n",
    "RMSE = mean_squared_error(Y_test, Y_test_pred)**0.5\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c387626",
   "metadata": {},
   "outputs": [],
   "source": [
    "#결과 값 엑셀 파일로 확인하기\n",
    "df_Y_test=pd.DataFrame(Y_test)\n",
    "df_Y_test_pred=pd.DataFrame(Y_test_pred)\n",
    "df_Y_train=pd.DataFrame(Y_train)\n",
    "df_Y_train_pred=pd.DataFrame(Y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "675758bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',200)\n",
    "df_Y_test.to_excel('55.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4d6dfc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',200)\n",
    "df_Y_test_pred.to_excel('66.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "130e6e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',200)\n",
    "df_Y_train.to_excel('77.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8ed46f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',200)\n",
    "df_Y_train_pred.to_excel('88.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
